# Task_01 Notes

## 1概念

机器学习：计算机通过学习算法，在海量的数据中寻找数学规律，并输出符合数据分布的模型。

Data Set（数据集）：一个关于某个事物或者对象的特征的描述的集合。集合里面每一个被称为样本（Sample）或者样例（instance）。例如：

特征（feature）、属性（attribute）：所描述对象或事物的性质或者属性。例如：”颜色“，”形状“等。

属性值（attribute value）：关于特征与属性的取值。例如：“青绿”、“椭圆”。

样本空间（sample space）、属性空间（attribute space）：由多个特征或属性组成的多维空间。每个特征作为一个维度的坐标轴。这样描述可以使得每个样本在空间里面有一个唯一对应的坐标点，所以样本也被叫做，“特征向量”（feature vector）。

学习（learning）、训练（training）：从数据中，使用学习方法获取模型的过程。

训练数据（training data）、训练样本（training sample）、训练集（training set）

假设（hypothesis）：假设学习的数据符合某种潜在的分布。

真相（ground-truth）：假设中潜在的规律。学习的过程就是找到最接近真相的模型。

标记（label）：样本的结果信息。“标记空间”

样例（example）：带有（label）的样本。

分类（classification）：模型根据输入的数据，输出离散预测值。二分类“binary classification”、多分类“Multi-class classification”

回归（regression）：模型根据输入的数据，输出连续预测值。

测试（test）：训练得到数据后，使用模型进行预测的过程。

测试样本（test sample）：被预测的样本，不带label。

聚类（cluster）：由于学习的样本没有标记，学习算法对这些样本进行自动分类。

泛化能力（generalization）：学习的模型，适应于新样本的能力。

独立同分布（independent and identically distributed，i.i.d）：在概率统计理论中，指随机过程中，任何时刻的取值都为随机变量，如果这些随机变量服从同一分布，并且互相独立，那么这些随机变量是独立同分布。

不同版本的假设空间输出的模型会产生不同的模型，学习就是就在所有的假设空间中搜索与训练集能够匹配上的过程。但是现实问题中，常常存在较大的假设空间，而训练的样本是有限的，从而有可能同一个训练集会有多个假设空间符合。最终导致误判。

归纳偏好（inductive bias）：机器学习算法在学习过程中对某种类型假设的偏好。也就是选择某一类“较容易识别”特征进行假设，完全取决于用户的偏好。

有可能发生的情况是：在某种假设情况下，能输出泛化能力很强的模型，在另一种假设的情况下，表现很糟糕。

## 2模型评估与选择

大声道
